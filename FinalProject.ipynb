{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProject.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOKGfvEnWKQL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#Encoding and Split data into Train/Test Sets\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "\n",
        "#Tensorflow Keras CNN Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#Plot Images\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "label = []\n",
        "\n",
        "for folder in os.listdir('../input/plant-seedlings-classification/train'):\n",
        "    for file in os.listdir(os.path.join('../input/plant-seedlings-classification/train', folder)):\n",
        "        label.append(folder)\n",
        "        img = cv2.imread(os.path.join('../input/plant-seedlings-classification/train', folder, file))\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        im = cv2.resize(img_rgb, (128,128))\n",
        "        data.append(im)"
      ],
      "metadata": {
        "id": "vdU1KmVzWZil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "label = np.array(label)"
      ],
      "metadata": {
        "id": "2PcWXwXIWZ1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data / 255"
      ],
      "metadata": {
        "id": "KHKcCykxZ9rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()"
      ],
      "metadata": {
        "id": "bFt-dKOsWb6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = encoder.fit_transform(label)\n",
        "y = to_categorical(y, 12)"
      ],
      "metadata": {
        "id": "vxNgO2twZ9Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "5SAwfIqcaKDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network"
      ],
      "metadata": {
        "id": "nUqdyO4sWqz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores = []\n",
        "histories = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (128,128,3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(12, activation = \"softmax\"))\n",
        "\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X[train], y[train],\n",
        "                batch_size=25,epochs=50,\n",
        "                verbose=1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "OFFf3sk3WdR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Neural Network"
      ],
      "metadata": {
        "id": "742RJKLVWs1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_d = []\n",
        "histories_d = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(200))\n",
        "    model.add(Dense(100))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dense(32)) \n",
        "    model.add(Dense(24))\n",
        "    model.add(Dense(16))\n",
        "    model.add(Dense(12, activation='softmax'))\n",
        "\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X[train], y[train],\n",
        "                batch_size=25,epochs=50,\n",
        "                verbose=1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "qBCuDl_lWoUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alex Net"
      ],
      "metadata": {
        "id": "vgrind4HWyWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_a = []\n",
        "histories_a = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(128,128,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.25)),\n",
        "    model.add(Dense(12, activation='softmax'))\n",
        "    \n",
        "    opt = Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X[train], y[train],\n",
        "                batch_size=25,epochs=50,\n",
        "                verbose=1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "arsytiFDWxx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet"
      ],
      "metadata": {
        "id": "pE61lQeJW7yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_res = []\n",
        "histories_res = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dense(32)) \n",
        "    model.add(Dense(24))\n",
        "    model.add(Dense(16))\n",
        "    model.add(Dense(12, activation='softmax'))\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X[train], y[train],\n",
        "                batch_size=25,epochs=50,\n",
        "                verbose=1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "iO0E8BYXW_cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding in Data Augmentation"
      ],
      "metadata": {
        "id": "lydn41TtXMqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        zoom_range = 0.20,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True)\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "NljZtymoXN6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network"
      ],
      "metadata": {
        "id": "3MvkfdjEXj0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores = []\n",
        "histories = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (128,128,3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(12, activation = \"softmax\"))\n",
        "\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "    model.fit_generator(datagen.flow(X_train,y_train, batch_size=25),epochs = 50,\n",
        "                                  validation_data = (X_test,y_test),verbose = 1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "fSMICiPOXgjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Neural Network"
      ],
      "metadata": {
        "id": "N9H6Gh84Xoh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_d = []\n",
        "histories_d = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(200))\n",
        "    model.add(Dense(100))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dense(32)) \n",
        "    model.add(Dense(24))\n",
        "    model.add(Dense(16))\n",
        "    model.add(Dense(12, activation='softmax'))\n",
        "\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "    model.fit_generator(datagen.flow(X_train,y_train, batch_size=25),epochs = 50,\n",
        "                                  validation_data = (X_test,y_test),verbose = 1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "IkJAY7PeXrDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet"
      ],
      "metadata": {
        "id": "rgPc7ksuX0a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_a = []\n",
        "histories_a = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(128,128,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.25)),\n",
        "    model.add(Dense(12, activation='softmax'))\n",
        "    \n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=25),epochs = 50,\n",
        "                                  validation_data = (X_test,y_test),verbose = 1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "qBFWRyboX1mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "dWjxE2SsX8AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_res = []\n",
        "histories_res = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dense(32)) \n",
        "    model.add(Dense(24))\n",
        "    model.add(Dense(16))\n",
        "    model.add(Dense(12, activation='softmax'))\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=25),epochs = 50,\n",
        "                                  validation_data = (X_test,y_test),verbose = 1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "nEniZIC8X9m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flower Classification"
      ],
      "metadata": {
        "id": "GlUgjbpBijGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network"
      ],
      "metadata": {
        "id": "0YwK_Pb-inuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores = []\n",
        "histories = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (128,128,3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(5, activation = \"softmax\"))\n",
        "\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X[train], y[train],\n",
        "                batch_size=25,epochs=50,\n",
        "                verbose=1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "qMlyICMGinur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Neural Network"
      ],
      "metadata": {
        "id": "NutGmQ9Hinur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_d = []\n",
        "histories_d = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(200))\n",
        "    model.add(Dense(100))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dense(32)) \n",
        "    model.add(Dense(24))\n",
        "    model.add(Dense(16))\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X[train], y[train],batch_size=25,epochs=50,verbose=1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "fiLM41DKinur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alex Net"
      ],
      "metadata": {
        "id": "YfzvEJvainus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_a = []\n",
        "histories_a = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(128,128,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.25)),\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    \n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X[train], y[train],batch_size=25,epochs=50,verbose=1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "AbFkBhboinus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet"
      ],
      "metadata": {
        "id": "QFDEdpb2inus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_res = []\n",
        "histories_res = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dense(32)) \n",
        "    model.add(Dense(24))\n",
        "    model.add(Dense(16))\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X[train], y[train],batch_size=25,epochs=50,verbose=1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "Vx9B2PtMinus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding in Data Augmentation"
      ],
      "metadata": {
        "id": "OqalzhPXinus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        zoom_range = 0.20,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True)\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "juOY8BOHinut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network"
      ],
      "metadata": {
        "id": "ekkWLO_kinut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores = []\n",
        "histories = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (128,128,3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(5, activation = \"softmax\"))\n",
        "\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=25),epochs = 50,\n",
        "                                  validation_data = (X_test,y_test),verbose = 1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "Cs6vWlceinut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dense Neural Network"
      ],
      "metadata": {
        "id": "3ohR2UG2inuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_d = []\n",
        "histories_d = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(200))\n",
        "    model.add(Dense(100))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dense(32)) \n",
        "    model.add(Dense(24))\n",
        "    model.add(Dense(16))\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=25),epochs = 50,\n",
        "                                  validation_data = (X_test,y_test),verbose = 1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "E-jHpvvAinuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet"
      ],
      "metadata": {
        "id": "7PiXCQeqinuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_a = []\n",
        "histories_a = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(128,128,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.25)),\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    \n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=25),epochs = 50,\n",
        "                                  validation_data = (X_test,y_test),verbose = 1)\n",
        "\n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "OYOPbY8dinuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "8IPIH0d4inuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=1234)\n",
        "cvscores_res = []\n",
        "histories_res = []\n",
        "for train, test in kfold.split(X, y):\n",
        "    model = Sequential()\n",
        "    model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dense(32)) \n",
        "    model.add(Dense(24))\n",
        "    model.add(Dense(16))\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=25),epochs = 50,\n",
        "                                  validation_data = (X_test,y_test),verbose = 1)\n",
        "    \n",
        "    scores = model.evaluate(X[test], y[test])\n",
        "\n",
        "    print(f'Score: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    histories.append(history)"
      ],
      "metadata": {
        "id": "HZLi8yziinuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions"
      ],
      "metadata": {
        "id": "gV87C3AkjVe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image"
      ],
      "metadata": {
        "id": "u384QUqdjUvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '../input/plant-seedlings-classification/test/0021e90e4.png'\n",
        "img = image.load_img(path, target_size=(128, 128))\n",
        "x = image.img_to_array(img)\n",
        "x = x / 255\n",
        "x = np.expand_dims(x, axis=0)\n",
        "classes = model.predict(x)\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "LPmX6bX5bkHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob = []\n",
        "for c in classes:\n",
        "    for p in c:\n",
        "        prob.append(p)"
      ],
      "metadata": {
        "id": "WOgctAIXbn6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = prob.index(max(prob))"
      ],
      "metadata": {
        "id": "VJz-IYtKbrX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "id": "rOZdnLH8bxG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob[index]"
      ],
      "metadata": {
        "id": "HZ_Pr9yUbx4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '../input/tulip-picture'\n",
        "img = image.load_img(path, target_size=(128, 128))\n",
        "x = image.img_to_array(img)\n",
        "x = x / 255\n",
        "x = np.expand_dims(x, axis=0)\n",
        "classes = model.predict(x)\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "TmWajw5cblgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob = []\n",
        "for c in classes:\n",
        "    for p in c:\n",
        "        prob.append(p)"
      ],
      "metadata": {
        "id": "lA8dpiXnbpfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = prob.index(max(prob))"
      ],
      "metadata": {
        "id": "NA5PaFXDbr3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "id": "QLPxcPDubua0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob[index]"
      ],
      "metadata": {
        "id": "dKeD3LQybuyW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}